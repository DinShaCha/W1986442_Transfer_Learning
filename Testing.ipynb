{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c533780-8f7c-41d7-8d49-8c6a12641c75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m852.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff470179-1747-4b22-a8f7-8d86ba406de9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow<2.17,>=2.16 (from tf-keras)\n",
      "  Downloading tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading h5py-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (23.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.8.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading grpcio-1.63.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading keras-3.3.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m190.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tf-keras) (0.41.2)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading optree-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m551.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2023.7.22)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (2.1.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (2.16.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m803.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0mm\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:--:--\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.63.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:--:--\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (312 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.0/312.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, opt-einsum, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow, tf-keras\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.5.4 google-pasta-0.2.0 grpcio-1.63.0 h5py-3.11.0 keras-3.3.3 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.8 numpy-1.26.4 opt-einsum-3.3.0 optree-0.11.0 protobuf-4.25.3 rich-13.7.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.37.0 termcolor-2.4.0 tf-keras-2.16.0 werkzeug-3.0.3 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f067c4c7-3fa0-41ec-b86b-5f2d49cae0da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tf_keras/src/initializers/initializers.py:121: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "Some layers from the model checkpoint at xlnet-large-cased were not used when initializing TFXLNetModel: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLNetModel were initialized from the model checkpoint at xlnet-large-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLNetModel for predictions without further training.\n",
      "2024-05-16 18:35:44.880983: E tensorflow/core/util/util.cc:131] oneDNN supports DT_INT32 only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFXLNetModelOutput(last_hidden_state=<tf.Tensor: shape=(1, 9, 1024), dtype=float32, numpy=\n",
      "array([[[-1.6709992 , -0.92030835, -1.1942148 , ..., -1.6724994 ,\n",
      "          0.70507467,  1.7064161 ],\n",
      "        [ 0.39474154, -0.11975965, -0.04046227, ..., -0.5282675 ,\n",
      "         -1.9147506 , -0.1750461 ],\n",
      "        [-1.5442853 , -1.2874888 ,  0.92295545, ..., -0.36155528,\n",
      "         -0.4873641 , -1.7736564 ],\n",
      "        ...,\n",
      "        [ 0.92353   , -1.45275   , -0.5797529 , ...,  0.29486322,\n",
      "         -1.7598855 , -3.4396791 ],\n",
      "        [-0.5873277 , -0.72206646, -0.07481501, ...,  1.6026444 ,\n",
      "          0.45974806,  1.1922643 ],\n",
      "        [-1.2288444 , -0.98621655, -0.9448048 , ..., -0.3093344 ,\n",
      "         -0.42924875,  2.2952054 ]]], dtype=float32)>, mems=(<tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.02717384,  0.04925968, -0.01368891, ..., -0.01682383,\n",
      "         -0.02933594, -0.00296901]],\n",
      "\n",
      "       [[ 0.06611059, -0.0034283 , -0.03228189, ..., -0.02002379,\n",
      "          0.03210833, -0.05285485]],\n",
      "\n",
      "       [[-0.02569832,  0.02679813,  0.01664192, ...,  0.00077819,\n",
      "         -0.02913301, -0.04272301]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.04447435,  0.02914356,  0.00182039, ...,  0.05218664,\n",
      "         -0.06505395, -0.04488529]],\n",
      "\n",
      "       [[ 0.07462703, -0.02518672,  0.08625317, ...,  0.00246533,\n",
      "         -0.03480605, -0.03043548]],\n",
      "\n",
      "       [[ 0.1157448 ,  0.00490346,  0.08931617, ...,  0.09165803,\n",
      "         -0.02251188, -0.11693592]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.7841832 ,  0.35904735,  0.19742863, ..., -0.33792412,\n",
      "         -1.0120544 ,  0.6836605 ]],\n",
      "\n",
      "       [[ 0.4760031 , -0.72781265,  0.18462916, ..., -0.545387  ,\n",
      "          0.45776737, -0.87502795]],\n",
      "\n",
      "       [[-0.6153122 , -0.05896984,  0.5488168 , ..., -0.21572992,\n",
      "          0.01196479, -0.22792874]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.33711636,  0.1056243 ,  0.53459805, ...,  0.33425823,\n",
      "         -1.7656275 , -0.6586665 ]],\n",
      "\n",
      "       [[ 0.7956192 , -1.1165209 ,  2.1640692 , ..., -0.20491529,\n",
      "         -0.7110854 , -0.4112341 ]],\n",
      "\n",
      "       [[ 1.3436215 , -0.7028794 ,  2.0294046 , ...,  1.4779425 ,\n",
      "         -0.65001655, -1.3446155 ]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.00669315,  0.01794656,  0.31338188, ..., -0.1419917 ,\n",
      "         -1.0003405 ,  0.6357838 ]],\n",
      "\n",
      "       [[ 0.04842597, -0.2503566 ,  0.5625802 , ..., -0.48741195,\n",
      "          0.7887249 , -0.42099193]],\n",
      "\n",
      "       [[-1.035929  , -0.24862139,  0.64655674, ..., -0.5587268 ,\n",
      "          0.18945917,  0.37750986]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.3443162 ,  0.99908304,  0.2615138 , ...,  0.43835786,\n",
      "         -1.6987752 , -0.36073616]],\n",
      "\n",
      "       [[ 0.79602957, -0.16123192,  2.6258233 , ..., -0.29650143,\n",
      "         -0.5529948 ,  0.9245038 ]],\n",
      "\n",
      "       [[ 1.4727919 , -0.25629118,  2.283559  , ...,  1.6983039 ,\n",
      "         -0.3949809 , -0.92266697]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.42254895, -0.34584984,  0.2585164 , ..., -0.4518976 ,\n",
      "         -0.14860454,  0.41562155]],\n",
      "\n",
      "       [[ 0.5254877 , -1.1207069 ,  0.33030105, ..., -0.8121967 ,\n",
      "          0.7552934 , -0.22350116]],\n",
      "\n",
      "       [[-0.9037611 , -0.66080654,  0.26527822, ..., -1.199753  ,\n",
      "          0.09566567,  0.05749339]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.9936929 ,  0.44645685, -0.1793111 , ..., -0.1415693 ,\n",
      "         -1.4088267 ,  0.07746918]],\n",
      "\n",
      "       [[ 0.82270277, -0.13260809,  2.332599  , ..., -0.18171073,\n",
      "         -0.665698  ,  0.7131915 ]],\n",
      "\n",
      "       [[ 1.4338301 , -0.0298984 ,  2.049295  , ...,  1.7321633 ,\n",
      "         -0.50886184, -0.88980055]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[ 0.09819207, -0.7916518 ,  0.2714182 , ...,  0.81556207,\n",
      "         -0.19370317,  0.666568  ]],\n",
      "\n",
      "       [[ 0.7734457 , -0.63573045,  0.35749796, ...,  0.40309748,\n",
      "          0.68733126,  0.20239455]],\n",
      "\n",
      "       [[-0.50266147, -0.975743  , -0.11382851, ..., -0.33399403,\n",
      "         -0.06764301,  0.51441824]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.796401  ,  0.01931738,  0.22289068, ...,  0.65546495,\n",
      "         -0.9835187 ,  0.5601875 ]],\n",
      "\n",
      "       [[ 0.8643538 ,  0.1240526 ,  1.7501589 , ...,  0.90664625,\n",
      "         -0.66981333,  1.0685478 ]],\n",
      "\n",
      "       [[ 1.4990332 ,  0.36276537,  1.9660426 , ...,  2.5494733 ,\n",
      "         -0.6280611 , -0.17661402]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[ 0.45472205, -0.51314205,  0.17469144, ...,  1.442558  ,\n",
      "         -0.09784187,  0.03948138]],\n",
      "\n",
      "       [[ 0.4194787 , -0.24073794, -0.11537512, ...,  1.0780281 ,\n",
      "          1.261168  ,  0.07230894]],\n",
      "\n",
      "       [[ 0.09231201, -0.89930314, -0.01614096, ...,  0.75687295,\n",
      "          0.5373438 ,  0.43460447]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.03958293, -0.4739226 ,  0.6163055 , ...,  0.6123863 ,\n",
      "          0.10218444, -0.04819468]],\n",
      "\n",
      "       [[ 0.79839724, -0.03205841,  1.9209439 , ...,  0.7193064 ,\n",
      "          0.14130646,  0.8772719 ]],\n",
      "\n",
      "       [[ 1.4096627 ,  0.08440091,  1.7162976 , ...,  1.7838877 ,\n",
      "         -0.2777067 , -0.10679036]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[ 0.4795027 , -0.28137636,  0.38996637, ...,  1.6067688 ,\n",
      "          0.68850136,  0.10563966]],\n",
      "\n",
      "       [[ 0.42795533, -0.26949635,  0.42874932, ...,  1.1013913 ,\n",
      "          1.6054856 , -0.10770515]],\n",
      "\n",
      "       [[ 0.38596228, -0.40068546,  0.6778946 , ...,  0.7150246 ,\n",
      "          0.8092342 ,  0.5326198 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.43618444, -0.0163587 ,  0.4928147 , ...,  0.7124014 ,\n",
      "          0.12756214,  0.27930754]],\n",
      "\n",
      "       [[ 0.9516927 , -0.07919382,  1.321789  , ...,  0.4787352 ,\n",
      "          0.29219893,  1.110707  ]],\n",
      "\n",
      "       [[ 1.3253317 ,  0.07785409,  0.8099812 , ...,  1.3442299 ,\n",
      "         -0.12957051,  0.37671107]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[ 0.0238118 , -0.61839485,  0.02045447, ...,  0.81099004,\n",
      "          0.9006454 , -0.6505649 ]],\n",
      "\n",
      "       [[-0.20661557,  0.10416373, -0.22154436, ...,  0.63403416,\n",
      "          1.4913278 , -0.5386084 ]],\n",
      "\n",
      "       [[ 0.2991921 , -0.2528745 ,  0.11813093, ...,  0.3665191 ,\n",
      "          0.76645124,  0.2812826 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.12974727, -0.48080304,  0.12643857, ...,  0.61131215,\n",
      "          0.07863915, -0.32662037]],\n",
      "\n",
      "       [[ 0.22584587, -0.1973253 ,  0.44248834, ...,  0.5376635 ,\n",
      "          0.2014238 ,  0.28057563]],\n",
      "\n",
      "       [[ 0.27060163,  0.09797776, -0.0513067 , ...,  1.1120714 ,\n",
      "         -0.02807051, -0.38722333]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.27116317, -0.5090743 , -0.6520857 , ...,  1.2015221 ,\n",
      "          0.74777496, -0.99421555]],\n",
      "\n",
      "       [[-0.49580076,  0.1934743 , -0.63559353, ...,  1.3083059 ,\n",
      "          1.1953391 , -0.6215084 ]],\n",
      "\n",
      "       [[-0.03557552,  0.09066775, -0.3692391 , ...,  0.93624413,\n",
      "          0.8126784 , -0.28189024]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.09737305, -0.34375608, -0.32468355, ...,  1.1413618 ,\n",
      "         -0.65404487, -0.19186358]],\n",
      "\n",
      "       [[ 0.41601804, -0.43886688, -0.01019846, ...,  1.0746944 ,\n",
      "         -0.63495857,  0.6916862 ]],\n",
      "\n",
      "       [[ 0.30603117, -0.21686561, -0.51605   , ...,  0.76644087,\n",
      "         -1.3449405 ,  0.13302739]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.6652657 , -0.41272566,  0.17615299, ...,  0.55904704,\n",
      "         -0.3841279 , -1.1425211 ]],\n",
      "\n",
      "       [[-0.51703537,  0.08155495,  0.42143175, ...,  0.89213604,\n",
      "         -0.01677859, -0.67396617]],\n",
      "\n",
      "       [[-0.09656453, -0.34139067,  0.58402836, ...,  0.47953734,\n",
      "         -0.45155162, -0.32334659]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.5271543 , -0.66393954,  0.365232  , ...,  0.8396455 ,\n",
      "         -1.5139592 ,  0.36311036]],\n",
      "\n",
      "       [[-0.28459907, -0.9357274 ,  0.6504115 , ...,  0.5999955 ,\n",
      "         -1.7081139 ,  0.91712   ]],\n",
      "\n",
      "       [[-0.6125382 , -0.23039672, -0.24413049, ...,  0.30824766,\n",
      "         -1.7560449 , -0.16835462]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.6744188 , -0.4564709 ,  0.06343141, ...,  0.24103798,\n",
      "         -0.16830073, -0.51942104]],\n",
      "\n",
      "       [[-0.58665276,  0.19405383,  0.02283179, ...,  0.56426805,\n",
      "          0.47849375, -0.54288125]],\n",
      "\n",
      "       [[-0.36140522, -0.73725456,  0.47957224, ...,  0.32430732,\n",
      "          0.04657169,  0.14814234]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.48338008, -0.47928607,  0.11144105, ...,  0.8669385 ,\n",
      "         -1.281095  ,  0.12799147]],\n",
      "\n",
      "       [[-0.21427158, -0.49994346,  0.972169  , ...,  0.568856  ,\n",
      "         -1.3002297 ,  0.88657755]],\n",
      "\n",
      "       [[-0.59071785, -0.15559998,  0.181216  , ...,  0.05318593,\n",
      "         -1.1094241 , -0.09203023]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.5749827 , -0.21423925, -0.00814611, ...,  0.50489336,\n",
      "         -0.23137102, -0.00946691]],\n",
      "\n",
      "       [[-0.44998732,  0.5247965 ,  0.28084052, ...,  0.7998777 ,\n",
      "          0.58424896, -0.10691512]],\n",
      "\n",
      "       [[-0.64467865, -0.05031736,  0.11314551, ...,  0.447385  ,\n",
      "         -0.26943684,  0.59924084]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.8879937 ,  0.1277749 , -0.7050233 , ...,  1.4292581 ,\n",
      "         -1.6012623 ,  0.65414643]],\n",
      "\n",
      "       [[-0.83837056,  0.08152637,  0.3449443 , ...,  0.77659947,\n",
      "         -1.4163988 ,  1.0163983 ]],\n",
      "\n",
      "       [[-1.159654  , -0.32779846,  0.12947294, ...,  0.41299602,\n",
      "         -1.6089739 ,  0.38259727]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.32162657,  0.61894923, -0.16143693, ...,  0.222889  ,\n",
      "          0.06750694, -0.05405784]],\n",
      "\n",
      "       [[-0.20181969,  1.25848   ,  0.11400278, ...,  0.84647393,\n",
      "          0.70176685, -0.21511218]],\n",
      "\n",
      "       [[-0.10074798,  0.14640808,  0.05463114, ...,  0.6040083 ,\n",
      "          0.18813014,  0.37411833]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.59094024,  0.3523919 , -0.5723669 , ...,  1.139379  ,\n",
      "         -0.9425512 ,  0.6865034 ]],\n",
      "\n",
      "       [[-0.52062196,  0.11243608,  0.43347317, ...,  0.39111826,\n",
      "         -0.9887926 ,  0.9960301 ]],\n",
      "\n",
      "       [[-0.6347756 , -0.0076613 , -0.15392798, ...,  0.13192202,\n",
      "         -1.2386886 ,  0.3803792 ]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.5693281 ,  0.7148404 , -0.328136  , ...,  0.19773531,\n",
      "          0.25189784, -0.30195534]],\n",
      "\n",
      "       [[-0.11272726,  0.6510099 , -0.30156678, ...,  0.49865597,\n",
      "          0.29560432,  0.03644624]],\n",
      "\n",
      "       [[-0.06732497, -0.27654937, -0.4422871 , ...,  0.33461323,\n",
      "         -0.3783234 ,  0.20614764]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.69821614,  0.62759274, -0.18763699, ...,  0.4439195 ,\n",
      "         -1.212446  , -0.03642933]],\n",
      "\n",
      "       [[-0.7475382 ,  0.04545298,  0.85954535, ...,  0.12795031,\n",
      "         -0.96299034,  0.40544695]],\n",
      "\n",
      "       [[-0.74798757, -0.42921162,  0.18576002, ...,  0.09935529,\n",
      "         -1.3198873 ,  0.25733903]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-1.0908386 ,  0.7217982 , -0.39356834, ...,  0.3361115 ,\n",
      "          0.6840652 , -0.11061581]],\n",
      "\n",
      "       [[-0.1239001 ,  0.65127265, -0.4412506 , ...,  0.60287225,\n",
      "          0.38908118,  0.01155307]],\n",
      "\n",
      "       [[-0.15667275, -0.06622116, -0.4270049 , ...,  0.13570662,\n",
      "         -0.04154617, -0.12926324]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.6372818 ,  0.24236563, -0.75201654, ...,  0.31753132,\n",
      "         -0.999787  ,  0.5666371 ]],\n",
      "\n",
      "       [[-0.42607218,  0.15760142,  0.40629402, ..., -0.0743878 ,\n",
      "         -0.67099726,  0.5833167 ]],\n",
      "\n",
      "       [[-0.48471436, -0.22927088, -0.15187886, ..., -0.12836519,\n",
      "         -0.81955993,  0.2575788 ]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.61542535, -0.00266393, -0.51942325, ..., -0.13847765,\n",
      "          0.59990764, -0.87789935]],\n",
      "\n",
      "       [[ 0.16086106,  0.19509265, -0.49506631, ...,  0.39294693,\n",
      "          0.19797747, -0.5255195 ]],\n",
      "\n",
      "       [[ 0.4284993 , -0.7048269 , -0.44311523, ..., -0.32696325,\n",
      "         -0.02607594, -0.69618917]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.2239782 , -0.25350776, -0.80983466, ...,  0.19942583,\n",
      "         -0.6918081 , -0.23298517]],\n",
      "\n",
      "       [[-0.05530392, -0.50213283,  0.4549276 , ..., -0.22170906,\n",
      "         -0.50531495,  0.12178669]],\n",
      "\n",
      "       [[-0.37965032, -1.1157098 , -0.24916406, ...,  0.01193313,\n",
      "         -0.5264759 ,  0.06583463]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.8476542 ,  0.11923904, -0.8668743 , ..., -0.4450733 ,\n",
      "          0.5247714 , -0.09664822]],\n",
      "\n",
      "       [[-0.09619087,  0.13932374, -0.29778093, ...,  0.25833842,\n",
      "         -0.00804956, -0.17410405]],\n",
      "\n",
      "       [[ 0.01259309, -0.88096434, -0.6552061 , ..., -0.15235555,\n",
      "         -0.11559303, -0.4306969 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.10637154, -0.17299183, -0.84030956, ...,  0.391389  ,\n",
      "         -0.7028032 , -0.04581058]],\n",
      "\n",
      "       [[-0.01089048, -0.45206314,  0.13748768, ..., -0.07746517,\n",
      "         -0.34551543, -0.01427979]],\n",
      "\n",
      "       [[-0.40183216, -1.1826427 , -0.30602056, ...,  0.12417874,\n",
      "         -0.8059933 ,  0.23995057]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.6284753 ,  0.10585821, -1.0433954 , ..., -0.33536193,\n",
      "          1.212934  ,  0.39420426]],\n",
      "\n",
      "       [[ 0.14078109, -0.0032267 , -0.21494322, ...,  0.11523838,\n",
      "          0.18018577,  0.08669908]],\n",
      "\n",
      "       [[ 0.27683097, -0.5832811 , -0.5949161 , ..., -0.5100864 ,\n",
      "          0.30122858, -0.38113037]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.27217674, -0.33784938, -1.1934754 , ...,  0.88664544,\n",
      "         -0.72153604,  0.19330476]],\n",
      "\n",
      "       [[ 0.4328117 , -0.46379814, -0.10222557, ...,  0.11493013,\n",
      "          0.05601887,  0.50563616]],\n",
      "\n",
      "       [[-0.3554794 , -1.1930262 , -0.2437422 , ..., -0.06768886,\n",
      "         -0.3074827 ,  0.64156264]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.41792685, -0.4648969 , -0.41505596, ..., -0.19848588,\n",
      "          1.4495777 ,  0.22502775]],\n",
      "\n",
      "       [[ 0.05745292, -0.06683164,  0.07274398, ...,  0.09641063,\n",
      "          0.13003296, -0.0124545 ]],\n",
      "\n",
      "       [[-0.09939145, -0.35160717,  0.07745635, ..., -0.7944685 ,\n",
      "         -0.42383868, -1.2554969 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.01821774, -0.57100755, -1.3335418 , ...,  1.3984456 ,\n",
      "         -0.6038666 ,  0.3103994 ]],\n",
      "\n",
      "       [[ 0.6832729 , -0.829674  , -0.39147633, ...,  0.20144044,\n",
      "          0.41058055,  0.3792515 ]],\n",
      "\n",
      "       [[-0.4642863 , -1.3932587 , -0.72500354, ...,  0.1202586 ,\n",
      "         -0.38403273,  0.5312175 ]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.47955224, -0.3579576 , -0.2725229 , ..., -0.15515195,\n",
      "          1.7189796 ,  0.40017438]],\n",
      "\n",
      "       [[ 0.02948496, -0.06756748, -0.01544585, ...,  0.02975457,\n",
      "          0.07045034,  0.04487209]],\n",
      "\n",
      "       [[-0.4691283 , -0.43818778, -0.3687893 , ..., -0.6702803 ,\n",
      "         -0.12337352, -1.0494525 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.6067546 , -0.9349457 , -1.2104664 , ...,  1.2806976 ,\n",
      "         -0.5050636 ,  0.36058545]],\n",
      "\n",
      "       [[ 0.7725542 , -0.8190267 , -0.2802515 , ...,  0.13636999,\n",
      "          0.40497652,  0.6777122 ]],\n",
      "\n",
      "       [[-0.1949906 , -1.2382864 , -0.74381167, ..., -0.23653507,\n",
      "         -0.2784197 ,  1.0444771 ]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-4.1393605e-01, -2.8125247e-01, -6.4759207e-01, ...,\n",
      "         -4.6690196e-02,  1.5177416e+00,  7.4470371e-02]],\n",
      "\n",
      "       [[ 1.8264672e-02, -3.7513692e-02, -6.8845473e-02, ...,\n",
      "          1.9064356e-02,  4.2496081e-02, -1.6223062e-03]],\n",
      "\n",
      "       [[-3.2603818e-01,  1.6370279e-01, -2.9080904e-01, ...,\n",
      "         -4.1608959e-01,  2.6658022e-01, -1.2070748e+00]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 5.7598507e-01, -1.0911608e+00, -1.2866844e+00, ...,\n",
      "          1.7004287e+00, -4.7550729e-01,  1.9141434e-01]],\n",
      "\n",
      "       [[ 8.4837699e-01, -1.2014139e+00, -3.3189723e-01, ...,\n",
      "          2.2833309e-01,  4.2086369e-01,  7.8199989e-01]],\n",
      "\n",
      "       [[-2.3936206e-01, -1.6313174e+00, -1.0058352e+00, ...,\n",
      "         -3.5913998e-01, -6.7270681e-02,  1.4575570e+00]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.23876022, -0.3762161 , -0.6630294 , ...,  0.16499761,\n",
      "          1.2295475 ,  0.08364186]],\n",
      "\n",
      "       [[-0.06520003,  0.07019782, -0.13790482, ..., -0.00707588,\n",
      "          0.05661573,  0.02447036]],\n",
      "\n",
      "       [[-0.40536267, -0.10810559, -0.29525676, ..., -0.48427457,\n",
      "          0.30049732, -1.2756898 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.66172034, -0.8233441 , -1.4318827 , ...,  1.3772874 ,\n",
      "         -0.51026744, -0.02975234]],\n",
      "\n",
      "       [[ 0.6912866 , -1.5444528 , -0.452787  , ...,  0.39665097,\n",
      "          0.38611397,  0.8086503 ]],\n",
      "\n",
      "       [[-0.31278697, -1.5679625 , -1.1652906 , ..., -0.45643884,\n",
      "         -0.13594379,  1.4463192 ]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.13539101, -0.2477587 , -0.46209332, ...,  0.00256824,\n",
      "          0.8918782 ,  0.17452689]],\n",
      "\n",
      "       [[ 0.00172462,  0.02007291, -0.05241488, ...,  0.00932941,\n",
      "          0.02390976,  0.00451723]],\n",
      "\n",
      "       [[-0.5852177 , -0.21170373, -0.26494724, ..., -0.6308484 ,\n",
      "          0.27921316, -1.3686978 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.20157075, -0.86355656, -1.3219968 , ...,  1.0716467 ,\n",
      "         -0.44874716, -0.1724088 ]],\n",
      "\n",
      "       [[ 0.52545875, -1.218595  , -0.51969814, ...,  0.273176  ,\n",
      "          0.1946671 ,  0.5238434 ]],\n",
      "\n",
      "       [[-0.19793038, -1.1898111 , -0.7422845 , ..., -0.46167037,\n",
      "         -0.19618809,  1.2425195 ]]], dtype=float32)>, <tf.Tensor: shape=(9, 1, 1024), dtype=float32, numpy=\n",
      "array([[[-0.13840047, -0.07056955, -0.39894444, ...,  0.09503922,\n",
      "          0.91411126,  0.5491455 ]],\n",
      "\n",
      "       [[ 0.03804532,  0.02169587, -0.1221605 , ...,  0.03791342,\n",
      "          0.0379511 , -0.03775067]],\n",
      "\n",
      "       [[-0.49741113, -0.5638124 , -0.11979669, ..., -0.07947563,\n",
      "          0.40468964, -0.8381158 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.4831093 , -0.87908375, -0.9081222 , ...,  0.67811614,\n",
      "         -0.52583647, -0.46519464]],\n",
      "\n",
      "       [[ 0.4238512 , -1.1172404 , -0.67412484, ...,  0.03791947,\n",
      "          0.36155352,  0.80106115]],\n",
      "\n",
      "       [[ 0.19563167, -1.2087754 , -0.7245663 , ..., -0.74757713,\n",
      "         -0.33376765,  1.5414841 ]]], dtype=float32)>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from transformers import XLNetTokenizer, TFXLNetModel\n",
    "\n",
    "# Use the correct model identifier from Hugging Face Model Hub\n",
    "model_name = 'xlnet-large-cased'\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = XLNetTokenizer.from_pretrained(model_name)\n",
    "model = TFXLNetModel.from_pretrained(model_name)\n",
    "\n",
    "# Example input text\n",
    "input_text = \"Hello, how are you?\"\n",
    "\n",
    "# Tokenize input\n",
    "inputs = tokenizer(input_text, return_tensors='tf')\n",
    "\n",
    "# Get model outputs\n",
    "outputs = model(inputs)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd94d01-91f2-4dfd-a8b9-361bbe88e99f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.41.0-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m116.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorflow in /opt/conda/lib/python3.11/site-packages (2.16.1)\n",
      "Collecting tensorflow-datasets\n",
      "  Downloading tensorflow_datasets-4.9.4-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m528.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:--:--\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (0.37.0)\n",
      "Collecting click (from tensorflow-datasets)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting dm-tree (from tensorflow-datasets)\n",
      "  Downloading dm_tree-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Collecting etils>=0.9.0 (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets)\n",
      "  Downloading etils-1.8.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting promise (from tensorflow-datasets)\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from tensorflow-datasets) (5.9.5)\n",
      "Collecting tensorflow-metadata (from tensorflow-datasets)\n",
      "  Downloading tensorflow_metadata-1.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting toml (from tensorflow-datasets)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting array-record>=0.5.0 (from tensorflow-datasets)\n",
      "  Downloading array_record-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (699 bytes)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Collecting fsspec (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: importlib_resources in /opt/conda/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (6.1.0)\n",
      "Requirement already satisfied: zipp in /opt/conda/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets) (3.17.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Collecting googleapis-common-protos<2,>=1.56.4 (from tensorflow-metadata->tensorflow-datasets)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Downloading transformers-4.41.0-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m918.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:01\u001b[0m00:01\u001b[0m0m/9.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_datasets-4.9.4-py3-none-any.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m628.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:01\u001b[0m00:01\u001b[0m0m[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[?25hDownloading array_record-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading etils-1.8.0-py3-none-any.whl (156 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.1/156.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.0/785.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dm_tree-0.1.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:--:--\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading tensorflow_metadata-1.15.0-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: promise\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21484 sha256=cfa8682449c6b7df3a3f9b9a9e80dbf232a86d0fa17c902f0600bca5911a553a\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/90/74/b1/9b54c896b8d9409e9268329d4d45ede8a8040abe91c8879932\n",
      "Successfully built promise\n",
      "Installing collected packages: dm-tree, toml, safetensors, regex, promise, googleapis-common-protos, fsspec, filelock, etils, click, tensorflow-metadata, huggingface-hub, tokenizers, transformers, array-record, tensorflow-datasets\n",
      "Successfully installed array-record-0.5.1 click-8.1.7 dm-tree-0.1.8 etils-1.8.0 filelock-3.14.0 fsspec-2024.5.0 googleapis-common-protos-1.63.0 huggingface-hub-0.23.0 promise-2.3 regex-2024.5.15 safetensors-0.4.3 tensorflow-datasets-4.9.4 tensorflow-metadata-1.15.0 tokenizers-0.19.1 toml-0.10.2 transformers-4.41.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers tensorflow tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c88fc6bd-d202-4ab7-a5e8-ed185b31c647",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in /opt/conda/lib/python3.11/site-packages (2.16.0)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in /opt/conda/lib/python3.11/site-packages (from tf-keras) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.8.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tf-keras) (0.41.2)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f6d6f9-05ce-4489-8242-c04725ecf1b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "451a3eba-0be7-4cab-993e-e6d12d85b2f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.11/site-packages (from jupyter) (7.0.6)\n",
      "Collecting qtconsole (from jupyter)\n",
      "  Downloading qtconsole-5.5.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jupyter-console (from jupyter)\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.11/site-packages (from jupyter) (7.9.2)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.11/site-packages (from jupyter) (6.25.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (8.16.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.11/site-packages (from ipywidgets) (5.11.2)\n",
      "Collecting widgetsnbextension~=4.0.10 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.10 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter) (1.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter) (8.4.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter) (5.4.0)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter) (1.5.8)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter) (25.1.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel->jupyter) (6.3.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jinja2>=3.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (3.1.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (0.2.2)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (3.0.1)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (0.8.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (5.9.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /opt/conda/lib/python3.11/site-packages (from nbconvert->jupyter) (1.2.1)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter) (2.8.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter) (2.25.0)\n",
      "Requirement already satisfied: jupyterlab<5,>=4.0.2 in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter) (4.0.7)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /opt/conda/lib/python3.11/site-packages (from notebook->jupyter) (0.2.3)\n",
      "Collecting qtpy>=2.4.0 (from qtconsole->jupyter)\n",
      "  Downloading QtPy-2.4.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.11/site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (3.11.0)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (4.0.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.8.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.4.4)\n",
      "Requirement already satisfied: overrides in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.17.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.17.1)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.11/site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (1.6.4)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab<5,>=4.0.2->notebook->jupyter) (2.0.4)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab<5,>=4.0.2->notebook->jupyter) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.10 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.13.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.9.14)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (4.19.1)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/conda/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.31.0)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.11/site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.18.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.8)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.10.6)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (0.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2023.7.22)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.11/site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter) (21.2.0)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.4)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /opt/conda/lib/python3.11/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.11/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.11/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.6.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.8.19.14)\n",
      "Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m566.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.0/215.0 kB\u001b[0m \u001b[31m749.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m703.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading qtconsole-5.5.2-py3-none-any.whl (123 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m799.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, qtpy, jupyterlab-widgets, ipywidgets, qtconsole, jupyter-console, jupyter\n",
      "Successfully installed ipywidgets-8.1.2 jupyter-1.0.0 jupyter-console-6.6.3 jupyterlab-widgets-3.0.10 qtconsole-5.5.2 qtpy-2.4.1 widgetsnbextension-4.0.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e92bb15-a4f7-4240-b4c5-49f73ec45be7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m174.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.4.2 scipy-1.13.0 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9209a471-e692-42f8-a33d-98406b5ab07a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "607f1a8c-59e5-4585-ad34-412be1a3e9cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m360.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c31569-6a42-4121-8393-c06e46f756ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tf_keras/src/initializers/initializers.py:121: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetForSequenceClassification: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFXLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary', 'logits_proj']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x7fd3899940e0> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function infer_framework at 0x7fd3899940e0> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0', 'tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0', 'tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0', 'tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0', 'tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-18 18:16:20.647015: E tensorflow/core/util/util.cc:131] oneDNN supports DT_INT32 only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 5777s 7s/step - loss: 0.4652 - accuracy: 0.8247 - val_loss: 0.4539 - val_accuracy: 0.8325\n",
      "Epoch 2/3\n",
      "776/776 [==============================] - 5299s 7s/step - loss: 0.4644 - accuracy: 0.8269 - val_loss: 0.4530 - val_accuracy: 0.8325\n",
      "Epoch 3/3\n",
      "776/776 [==============================] - 4295s 6s/step - loss: 0.4636 - accuracy: 0.8253 - val_loss: 0.4698 - val_accuracy: 0.8325\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import XLNetTokenizer, TFXLNetForSequenceClassification\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"/home/jovyan/work/preprocessed_reviews.xlsx\"\n",
    "print(\"File exists:\", os.path.isfile(file_path))\n",
    "\n",
    "# Load the entire dataset\n",
    "dataset = pd.read_excel(file_path)\n",
    "\n",
    "# Reduce batch size\n",
    "batch_size = 4\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(dataset['texts'].tolist(), dataset['labels'].tolist(), test_size=0.2, random_state=42)\n",
    "\n",
    "# Clear the dataset from memory\n",
    "del dataset\n",
    "gc.collect()\n",
    "\n",
    "# Load the XLNet tokenizer\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "\n",
    "# Set max_length for tokenization\n",
    "max_length = 128\n",
    "\n",
    "# Tokenize input texts in chunks to manage memory\n",
    "def tokenize_texts(texts, tokenizer, max_length=128):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        chunk = texts[i:i+batch_size]\n",
    "        encodings = tokenizer(chunk, truncation=True, padding='max_length', max_length=max_length)\n",
    "        input_ids.extend(encodings['input_ids'])\n",
    "        attention_mask.extend(encodings['attention_mask'])\n",
    "        # Clear memory\n",
    "        del encodings\n",
    "        gc.collect()\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "train_encodings = tokenize_texts(train_texts, tokenizer, max_length=max_length)\n",
    "val_encodings = tokenize_texts(val_texts, tokenizer, max_length=max_length)\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    ")).shuffle(1000).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    ")).batch(batch_size)\n",
    "\n",
    "# Clear unnecessary variables\n",
    "del train_texts, val_texts, train_labels, val_labels, train_encodings, val_encodings\n",
    "gc.collect()\n",
    "\n",
    "# Define the model architecture\n",
    "model = TFXLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=2)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ebd4af-1465-45d8-9a39-023b9f7ef997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.41.0-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m202.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.2.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Downloading h5py-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow) (4.8.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.63.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Downloading keras-3.3.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m481.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:--:--\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.0->transformers)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Downloading optree-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m650.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.0.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading transformers-4.41.0-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m320.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.16.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m231.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:15\u001b[0mm\n",
      "\u001b[?25hDownloading scikit_learn-1.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m178.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m398.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.63.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m285.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m547.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m996.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m676.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m998.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m967.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.0/785.0 kB\u001b[0m \u001b[31m661.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m292.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m468.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m197.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m118.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m197.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m506.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.6-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m164.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m387.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (312 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.0/312.0 kB\u001b[0m \u001b[31m921.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m997.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m630.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, scipy, safetensors, regex, protobuf, optree, opt-einsum, ml-dtypes, mdurl, markdown, joblib, h5py, grpcio, google-pasta, gast, fsspec, filelock, astunparse, absl-py, tensorboard, scikit-learn, markdown-it-py, huggingface-hub, tokenizers, rich, transformers, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 filelock-3.14.0 flatbuffers-24.3.25 fsspec-2024.5.0 gast-0.5.4 google-pasta-0.2.0 grpcio-1.63.0 h5py-3.11.0 huggingface-hub-0.23.0 joblib-1.4.2 keras-3.3.3 libclang-18.1.1 markdown-3.6 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.8 opt-einsum-3.3.0 optree-0.11.0 protobuf-4.25.3 regex-2024.5.15 rich-13.7.1 safetensors-0.4.3 scikit-learn-1.4.2 scipy-1.13.0 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.37.0 termcolor-2.4.0 threadpoolctl-3.5.0 tokenizers-0.19.1 transformers-4.41.0 werkzeug-3.0.3 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers tensorflow pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2386d861-954a-4cf8-aa25-5ea483151a1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (4.41.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da6dc20-e3fe-4714-961c-829552960703",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 19:22:51.579857: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-19 19:22:51.585789: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-19 19:22:51.690309: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-19 19:22:52.223200: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-19 19:22:54.545744: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.11/site-packages/tf_keras/src/initializers/initializers.py:121: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetForSequenceClassification: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFXLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary', 'logits_proj']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.11/site-packages/tf_keras/src/backend.py:5729: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0', 'tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0', 'tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0', 'tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfxl_net_for_sequence_classification/transformer/mask_emb:0', 'tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._0/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._1/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._1/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._2/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._2/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._3/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._3/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._4/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._4/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._5/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._5/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._6/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._6/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._7/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._7/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._8/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._8/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._9/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._9/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._10/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._10/rel_attn/seg_embed:0', 'tfxl_net_for_sequence_classification/transformer/layer_._11/rel_attn/r_s_bias:0', 'tfxl_net_for_sequence_classification/transformer/layer_._11/rel_attn/seg_embed:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 19:26:27.285254: E tensorflow/core/util/util.cc:131] oneDNN supports DT_INT32 only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776/776 [==============================] - 3137s 4s/step - loss: 0.4704 - accuracy: 0.8012 - val_loss: 0.4233 - val_accuracy: 0.8325\n",
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7f276bffea10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7f276b79e010>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7f276b703290>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7f276b764e10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7f276b6da6d0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7f276b745650>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7f276c445050>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7f276b744150>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7f276b5dff10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7f276c425e90>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7f276b5e6a10>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of TF-Keras layer <tf_keras.src.layers.regularization.dropout.Dropout object at 0x7f276c446ed0>, because it is not built.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import XLNetTokenizer, TFXLNetForSequenceClassification\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"/home/jovyan/work/preprocessed_reviews.xlsx\"\n",
    "print(\"File exists:\", os.path.isfile(file_path))\n",
    "\n",
    "# Load the entire dataset\n",
    "dataset = pd.read_excel(file_path)\n",
    "\n",
    "# Reduce batch size\n",
    "batch_size = 4\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(dataset['texts'].tolist(), dataset['labels'].tolist(), test_size=0.2, random_state=42)\n",
    "\n",
    "# Clear the dataset from memory\n",
    "del dataset\n",
    "\n",
    "# Load the XLNet tokenizer\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "\n",
    "# Set max_length for tokenization\n",
    "max_length = 128\n",
    "\n",
    "# Tokenize input texts in chunks to manage memory\n",
    "def tokenize_texts(texts, tokenizer, max_length=128):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        chunk = texts[i:i+batch_size]\n",
    "        encodings = tokenizer(chunk, truncation=True, padding='max_length', max_length=max_length)\n",
    "        input_ids.extend(encodings['input_ids'])\n",
    "        attention_mask.extend(encodings['attention_mask'])\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "train_encodings = tokenize_texts(train_texts, tokenizer, max_length=max_length)\n",
    "val_encodings = tokenize_texts(val_texts, tokenizer, max_length=max_length)\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    train_encodings,\n",
    "    train_labels\n",
    ")).shuffle(1000).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    val_encodings,\n",
    "    val_labels\n",
    ")).batch(batch_size)\n",
    "\n",
    "# Define the XLNet model architecture\n",
    "xlnet_model = TFXLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=2)\n",
    "\n",
    "# Define additional layers for classification\n",
    "dense_layer1 = tf.keras.layers.Dense(512, activation='relu')\n",
    "dropout_layer1 = tf.keras.layers.Dropout(0.5)\n",
    "dense_layer2 = tf.keras.layers.Dense(256, activation='relu')\n",
    "dropout_layer2 = tf.keras.layers.Dropout(0.3)\n",
    "output_layer = tf.keras.layers.Dense(2, activation='softmax')\n",
    "\n",
    "# Build the model\n",
    "inputs = tf.keras.Input(shape=(max_length,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_masks = tf.keras.Input(shape=(max_length,), dtype=tf.int32, name=\"attention_mask\")\n",
    "xlnet_output = xlnet_model({'input_ids': inputs, 'attention_mask': input_masks})\n",
    "logits = xlnet_output.logits\n",
    "x = tf.keras.layers.Reshape((-1, logits.shape[-1]))(logits)  # Reshape logits tensor\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = dense_layer1(x)\n",
    "x = dropout_layer1(x)\n",
    "x = dense_layer2(x)\n",
    "x = dropout_layer2(x)\n",
    "outputs = output_layer(x)\n",
    "\n",
    "# Compile the model\n",
    "model = tf.keras.Model(inputs=[inputs, input_masks], outputs=outputs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=1)\n",
    "\n",
    "# Save the improved model\n",
    "model.save(\"/home/jovyan/work/improved_xlnet_model\")\n",
    "\n",
    "# Test a sentence with the improved model\n",
    "test_sentence = \"This product is terrible!\"\n",
    "inputs = tokenizer(test_sentence, return_tensors=\"tf\", truncation=True, padding='max_length', max_length=128)\n",
    "output = model([inputs['input_ids'], inputs['attention_mask']])\n",
    "probabilities = tf.nn.softmax(output)\n",
    "probabilities_np = probabilities.numpy()\n",
    "predicted_label = np.argmax(probabilities_np, axis=-1)[0]\n",
    "\n",
    "# Print the results\n",
    "label_names = ['negative', 'positive']  # Adjust according to your actual label names\n",
    "print(f\"Sentence: {test_sentence}\")\n",
    "print(f\"Predicted label: {label_names[predicted_label]}\")\n",
    "print(f\"Probabilities: {probabilities_np}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
